{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Credit Card Approval",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsrHmmCkX7yD"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "8CNOSN5aYCmT",
        "outputId": "d783e0c5-4f25-4c6a-bea5-aa516d2edeec"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c8e6aecb-b001-432a-8e09-901ed5d0daf9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c8e6aecb-b001-432a-8e09-901ed5d0daf9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving cc_approvals.data.txt to cc_approvals.data.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkiMx3mlYJos"
      },
      "source": [
        "import io\n",
        "cc_apps = pd.read_csv(io.BytesIO(uploaded['crx.data']),header=None)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "6xh52cdDYdV2",
        "outputId": "79a3bc1f-161a-4063-e9d5-f2ddf60c8fee"
      },
      "source": [
        "cc_apps.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b</td>\n",
              "      <td>30.83</td>\n",
              "      <td>0.000</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>w</td>\n",
              "      <td>v</td>\n",
              "      <td>1.25</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>1</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>00202</td>\n",
              "      <td>0</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a</td>\n",
              "      <td>58.67</td>\n",
              "      <td>4.460</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>q</td>\n",
              "      <td>h</td>\n",
              "      <td>3.04</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>6</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>00043</td>\n",
              "      <td>560</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a</td>\n",
              "      <td>24.50</td>\n",
              "      <td>0.500</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>q</td>\n",
              "      <td>h</td>\n",
              "      <td>1.50</td>\n",
              "      <td>t</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>00280</td>\n",
              "      <td>824</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>b</td>\n",
              "      <td>27.83</td>\n",
              "      <td>1.540</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>w</td>\n",
              "      <td>v</td>\n",
              "      <td>3.75</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>5</td>\n",
              "      <td>t</td>\n",
              "      <td>g</td>\n",
              "      <td>00100</td>\n",
              "      <td>3</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b</td>\n",
              "      <td>20.17</td>\n",
              "      <td>5.625</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>w</td>\n",
              "      <td>v</td>\n",
              "      <td>1.71</td>\n",
              "      <td>t</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>f</td>\n",
              "      <td>s</td>\n",
              "      <td>00120</td>\n",
              "      <td>0</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  0      1      2  3  4  5  6     7  8  9   10 11 12     13   14 15\n",
              "0  b  30.83  0.000  u  g  w  v  1.25  t  t   1  f  g  00202    0  +\n",
              "1  a  58.67  4.460  u  g  q  h  3.04  t  t   6  f  g  00043  560  +\n",
              "2  a  24.50  0.500  u  g  q  h  1.50  t  f   0  f  g  00280  824  +\n",
              "3  b  27.83  1.540  u  g  w  v  3.75  t  t   5  t  g  00100    3  +\n",
              "4  b  20.17  5.625  u  g  w  v  1.71  t  f   0  f  s  00120    0  +"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "HviQsbLPYh92",
        "outputId": "e211dc08-452c-4cc4-a75f-7458f36a86d3"
      },
      "source": [
        "cc_apps.describe()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>2</th>\n",
              "      <th>7</th>\n",
              "      <th>10</th>\n",
              "      <th>14</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>690.000000</td>\n",
              "      <td>690.000000</td>\n",
              "      <td>690.00000</td>\n",
              "      <td>690.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>4.758725</td>\n",
              "      <td>2.223406</td>\n",
              "      <td>2.40000</td>\n",
              "      <td>1017.385507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>4.978163</td>\n",
              "      <td>3.346513</td>\n",
              "      <td>4.86294</td>\n",
              "      <td>5210.102598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.165000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2.750000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>7.207500</td>\n",
              "      <td>2.625000</td>\n",
              "      <td>3.00000</td>\n",
              "      <td>395.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>28.000000</td>\n",
              "      <td>28.500000</td>\n",
              "      <td>67.00000</td>\n",
              "      <td>100000.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               2           7          10             14\n",
              "count  690.000000  690.000000  690.00000     690.000000\n",
              "mean     4.758725    2.223406    2.40000    1017.385507\n",
              "std      4.978163    3.346513    4.86294    5210.102598\n",
              "min      0.000000    0.000000    0.00000       0.000000\n",
              "25%      1.000000    0.165000    0.00000       0.000000\n",
              "50%      2.750000    1.000000    0.00000       5.000000\n",
              "75%      7.207500    2.625000    3.00000     395.500000\n",
              "max     28.000000   28.500000   67.00000  100000.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63_a_A5eYpVl",
        "outputId": "46d536e7-1f41-4429-c11e-3ba460bbe4d7"
      },
      "source": [
        "cc_apps.isnull().sum()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     0\n",
              "1     0\n",
              "2     0\n",
              "3     0\n",
              "4     0\n",
              "5     0\n",
              "6     0\n",
              "7     0\n",
              "8     0\n",
              "9     0\n",
              "10    0\n",
              "11    0\n",
              "12    0\n",
              "13    0\n",
              "14    0\n",
              "15    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MItl-igYuBe",
        "outputId": "2bfd62a9-6448-4ba9-999e-252a410971e0"
      },
      "source": [
        "cc_apps.info()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 690 entries, 0 to 689\n",
            "Data columns (total 16 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   0       690 non-null    object \n",
            " 1   1       690 non-null    object \n",
            " 2   2       690 non-null    float64\n",
            " 3   3       690 non-null    object \n",
            " 4   4       690 non-null    object \n",
            " 5   5       690 non-null    object \n",
            " 6   6       690 non-null    object \n",
            " 7   7       690 non-null    float64\n",
            " 8   8       690 non-null    object \n",
            " 9   9       690 non-null    object \n",
            " 10  10      690 non-null    int64  \n",
            " 11  11      690 non-null    object \n",
            " 12  12      690 non-null    object \n",
            " 13  13      690 non-null    object \n",
            " 14  14      690 non-null    int64  \n",
            " 15  15      690 non-null    object \n",
            "dtypes: float64(2), int64(2), object(12)\n",
            "memory usage: 86.4+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTBj4CppY60S",
        "outputId": "3e0142f3-b0af-4276-c646-db60bcfbb40a"
      },
      "source": [
        "for x in cc_apps.columns:\n",
        "  print(x, cc_apps[x].unique())\n",
        "  ## we have got ? so replace it with nan and fillna"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 ['b' 'a' '?']\n",
            "1 ['30.83' '58.67' '24.50' '27.83' '20.17' '32.08' '33.17' '22.92' '54.42'\n",
            " '42.50' '22.08' '29.92' '38.25' '48.08' '45.83' '36.67' '28.25' '23.25'\n",
            " '21.83' '19.17' '25.00' '47.75' '27.42' '41.17' '15.83' '47.00' '56.58'\n",
            " '57.42' '42.08' '29.25' '42.00' '49.50' '36.75' '22.58' '27.25' '23.00'\n",
            " '27.75' '54.58' '34.17' '28.92' '29.67' '39.58' '56.42' '54.33' '41.00'\n",
            " '31.92' '41.50' '23.92' '25.75' '26.00' '37.42' '34.92' '34.25' '23.33'\n",
            " '23.17' '44.33' '35.17' '43.25' '56.75' '31.67' '23.42' '20.42' '26.67'\n",
            " '36.00' '25.50' '19.42' '32.33' '34.83' '38.58' '44.25' '44.83' '20.67'\n",
            " '34.08' '21.67' '21.50' '49.58' '27.67' '39.83' '?' '37.17' '25.67'\n",
            " '34.00' '49.00' '62.50' '31.42' '52.33' '28.75' '28.58' '22.50' '28.50'\n",
            " '37.50' '35.25' '18.67' '54.83' '40.92' '19.75' '29.17' '24.58' '33.75'\n",
            " '25.42' '37.75' '52.50' '57.83' '20.75' '39.92' '24.75' '44.17' '23.50'\n",
            " '47.67' '22.75' '34.42' '28.42' '67.75' '47.42' '36.25' '32.67' '48.58'\n",
            " '33.58' '18.83' '26.92' '31.25' '56.50' '43.00' '22.33' '32.83' '40.33'\n",
            " '30.50' '52.83' '46.67' '58.33' '37.33' '23.08' '32.75' '68.67' '28.00'\n",
            " '44.00' '25.08' '32.00' '60.58' '40.83' '19.33' '41.33' '56.00' '49.83'\n",
            " '22.67' '27.00' '26.08' '18.42' '21.25' '57.08' '22.42' '48.75' '40.00'\n",
            " '40.58' '28.67' '33.08' '21.33' '41.75' '34.50' '48.17' '27.58' '24.08'\n",
            " '24.83' '36.33' '35.42' '71.58' '39.50' '39.33' '24.33' '60.08' '55.92'\n",
            " '53.92' '18.92' '50.08' '65.42' '17.58' '18.08' '19.67' '25.17' '33.50'\n",
            " '58.42' '26.17' '42.83' '38.17' '20.50' '48.25' '28.33' '18.75' '18.50'\n",
            " '45.00' '40.25' '41.42' '17.83' '18.17' '20.00' '52.17' '50.75' '17.08'\n",
            " '18.33' '59.67' '18.00' '37.58' '30.67' '18.58' '16.25' '21.17' '17.67'\n",
            " '16.50' '29.50' '21.75' '18.25' '35.75' '16.08' '69.17' '32.92' '16.33'\n",
            " '22.17' '57.58' '15.92' '31.75' '19.00' '17.50' '33.67' '30.17' '33.25'\n",
            " '25.25' '34.75' '47.33' '39.08' '42.75' '38.92' '62.75' '32.25' '26.75'\n",
            " '63.33' '30.75' '16.00' '19.50' '32.42' '30.25' '26.83' '16.92' '24.42'\n",
            " '39.42' '23.58' '21.42' '33.00' '26.33' '26.25' '28.17' '20.83' '43.17'\n",
            " '56.83' '15.17' '29.83' '31.00' '51.92' '69.50' '19.58' '22.25' '38.42'\n",
            " '26.58' '35.00' '29.42' '49.17' '51.83' '58.58' '53.33' '27.17' '25.92'\n",
            " '30.58' '17.25' '27.33' '36.50' '29.75' '52.42' '36.17' '34.58' '21.92'\n",
            " '36.58' '31.08' '30.42' '21.08' '17.42' '39.17' '26.50' '17.33' '23.75'\n",
            " '34.67' '74.83' '45.33' '47.25' '24.17' '39.25' '39.00' '64.08' '31.33'\n",
            " '21.00' '13.75' '46.00' '20.25' '60.92' '30.00' '22.83' '45.17' '41.58'\n",
            " '55.75' '25.33' '31.83' '33.92' '24.92' '80.25' '30.08' '48.33' '76.75'\n",
            " '51.33' '41.92' '29.58' '32.17' '51.42' '42.17' '43.08' '59.50' '65.17'\n",
            " '20.33' '48.50' '28.08' '73.42' '51.58' '38.67' '46.08' '20.08' '42.25'\n",
            " '16.17' '47.83' '22.00' '38.33' '25.58' '21.58' '36.08' '38.75' '35.58'\n",
            " '31.58' '15.75' '17.92' '30.33' '47.17' '25.83' '50.25' '36.42']\n",
            "2 [ 0.     4.46   0.5    1.54   5.625  4.     1.04  11.585  4.915  0.83\n",
            "  1.835  6.     6.04  10.5    4.415  0.875  5.875  0.25   8.585 11.25\n",
            "  1.     8.    14.5    6.5    0.585 13.    18.5    8.5   14.79   9.79\n",
            "  7.585  5.125 10.75   1.5    1.585 11.75   9.415  9.17  15.     1.415\n",
            " 13.915 28.     6.75   2.04   0.665  2.5    3.    11.625  4.5   12.25\n",
            " 16.165  0.79   0.835  4.25   0.375 25.125  7.5    5.     7.     5.29\n",
            "  1.165  9.75  19.     3.5    0.625  2.21  12.75  15.5    1.375  3.54\n",
            " 11.     1.75  16.5   12.     2.25   0.75  12.5    1.25   1.125  7.04\n",
            " 10.335  6.21   6.665  9.     5.5    0.54   2.75   9.5   13.5    3.75\n",
            " 16.     0.29   1.665  7.54   0.46  10.    11.5    3.04   2.     0.08\n",
            "  1.71   3.25   2.54  13.585  8.665  9.25   8.17   2.335 19.5    5.665\n",
            "  4.625  0.205  0.96   4.04   5.04   3.165  7.625 10.04  10.25   2.125\n",
            "  9.335  6.625  2.71   9.625 12.54   9.54   8.46  13.75  21.    10.125\n",
            " 25.085  0.21  21.5   11.125 11.045  1.335  0.085  1.21   0.165  5.71\n",
            "  5.415 12.625  0.58   0.415  2.415  0.335  3.125 12.125  2.875 13.665\n",
            " 26.335 10.29   1.29  22.     0.125  1.085  4.085  4.71   6.165  4.585\n",
            " 11.46  14.585  0.17   1.625  2.085  5.085  8.125  2.835  1.79   0.705\n",
            "  2.165  2.29  18.125  3.085 11.665  4.125  1.08  13.335 11.835  4.79\n",
            "  9.96   7.08  25.21   0.67   3.79  22.29   3.335  0.42   1.46   0.04\n",
            " 12.33  12.335  0.915 14.    17.75  20.     5.25   4.165 10.915  4.75\n",
            " 10.415  7.835  0.71   2.46   9.585  3.625  2.665  5.835 12.835 10.665\n",
            "  7.25  10.21   3.29  10.085  3.375]\n",
            "3 ['u' 'y' '?' 'l']\n",
            "4 ['g' 'p' '?' 'gg']\n",
            "5 ['w' 'q' 'm' 'r' 'cc' 'k' 'c' 'd' 'x' 'i' 'e' 'aa' 'ff' 'j' '?']\n",
            "6 ['v' 'h' 'bb' 'ff' 'j' 'z' '?' 'o' 'dd' 'n']\n",
            "7 [ 1.25   3.04   1.5    3.75   1.71   2.5    6.5    0.04   3.96   3.165\n",
            "  2.165  4.335  1.     5.     0.25   0.96   3.17   0.665  0.75   0.835\n",
            "  7.875  3.085  0.5    5.165 15.     7.     5.04   7.96   7.585  0.415\n",
            "  2.     1.835 14.415  4.5    5.335  8.625 28.5    2.625  0.125  6.04\n",
            "  3.5    0.165  0.875  1.75   0.     7.415  0.085  5.75   6.     3.\n",
            "  1.585  4.29   1.54   1.46   1.625 12.5   13.5   10.75   0.375  0.585\n",
            "  0.455  4.     8.5    9.46   2.25  10.     0.795  1.375  1.29  11.5\n",
            "  6.29  14.     0.335  1.21   7.375  7.5    3.25  13.     5.5    4.25\n",
            "  0.625  5.085  2.75   2.375  8.     1.085  2.54   4.165  1.665 11.\n",
            "  9.     1.335  1.415  1.96   2.585  5.125 15.5    0.71   5.665 18.\n",
            "  5.25   8.665  2.29  20.     2.46  13.875  2.085  4.58   2.71   2.04\n",
            "  0.29   4.75   0.46   0.21   0.54   3.335  2.335  1.165  2.415  2.79\n",
            "  4.625  1.04   6.75   1.875 16.    12.75   5.375  2.125 17.5    3.125\n",
            "  0.79   8.29 ]\n",
            "8 ['t' 'f']\n",
            "9 ['t' 'f']\n",
            "10 [ 1  6  0  5  7 10  3 17  2  9  8 15 11 12 40 23  4 20 67 14 16 13 19]\n",
            "11 ['f' 't']\n",
            "12 ['g' 's' 'p']\n",
            "13 ['00202' '00043' '00280' '00100' '00120' '00360' '00164' '00080' '00180'\n",
            " '00052' '00128' '00260' '00000' '00320' '00396' '00096' '00200' '00300'\n",
            " '00145' '00500' '00168' '00434' '00583' '00030' '00240' '00070' '00455'\n",
            " '00311' '00216' '00491' '00400' '00239' '00160' '00711' '00250' '00520'\n",
            " '00515' '00420' '?' '00980' '00443' '00140' '00094' '00368' '00288'\n",
            " '00928' '00188' '00112' '00171' '00268' '00167' '00075' '00152' '00176'\n",
            " '00329' '00212' '00410' '00274' '00375' '00408' '00350' '00204' '00040'\n",
            " '00181' '00399' '00440' '00093' '00060' '00395' '00393' '00021' '00029'\n",
            " '00102' '00431' '00370' '00024' '00020' '00129' '00510' '00195' '00144'\n",
            " '00380' '00049' '00050' '00381' '00150' '00117' '00056' '00211' '00230'\n",
            " '00156' '00022' '00228' '00519' '00253' '00487' '00220' '00088' '00073'\n",
            " '00121' '00470' '00136' '00132' '00292' '00154' '00272' '00340' '00108'\n",
            " '00720' '00450' '00232' '00170' '01160' '00411' '00460' '00348' '00480'\n",
            " '00640' '00372' '00276' '00221' '00352' '00141' '00178' '00600' '00550'\n",
            " '02000' '00225' '00210' '00110' '00356' '00045' '00062' '00092' '00174'\n",
            " '00017' '00086' '00454' '00254' '00028' '00263' '00333' '00312' '00290'\n",
            " '00371' '00099' '00252' '00760' '00560' '00130' '00523' '00680' '00163'\n",
            " '00208' '00383' '00330' '00422' '00840' '00432' '00032' '00186' '00303'\n",
            " '00349' '00224' '00369' '00076' '00231' '00309' '00416' '00465' '00256']\n",
            "14 [     0    560    824      3  31285   1349    314   1442    200   2690\n",
            "    245   1208   1260     11  10000   5000   4000     35    713    551\n",
            "    500    300    221   2283    100     15    284   1236   5800    730\n",
            "    400  50000    456  15108   2954      2     20     27    225      1\n",
            "     38      5    130    147    210  11202   1332     50    258    567\n",
            "   1000   2510    809    610    150  51100    367    600    247    375\n",
            "    278    827   2072    582   2300   3065   2200      6   1602   2184\n",
            "   3376   2000   7544  10561    837  11177    639   2028   1065    540\n",
            "    158  15000   3000   3257   1655   1430      7    790    396    678\n",
            "   1187   6590    168   1270   1210    742   8851   7059   1704    857\n",
            "   6700   2503   9800    196     14  26726  18027     99    444   1200\n",
            "   2010     13    120     32    722     40    484    204     98   5552\n",
            "    105   2803    126      4     21    173     10     25     42 100000\n",
            "    113      8     44   2732    179     16   1062    251    228     67\n",
            "     12    122   4208   1300    112   1110   1004    286   4500   1212\n",
            "    195     87     17    184    140     18    146     22     55     70\n",
            "     60   1058    769   5200     19    316    350   3552    687   1950\n",
            "     53     41     33     80    351   2100    475    892   4607   2206\n",
            "   5860     28   1391   2279    591    960    690    234    800    990\n",
            "   2197     90    340    347    327   4071    109   1249    134   1344\n",
            "    321    948   2079   2384    458   5298    162   1583     58     59\n",
            "   1400   1465   8000   4700   1097   3290  13212   5777   5124     23\n",
            "   4159    918    768    283    108      9     68    587    141    501\n",
            "    160    390    154    117    246    237    364    537    394    750]\n",
            "15 ['+' '-']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0prtuBSZj15"
      },
      "source": [
        "import numpy as np\n",
        "# Replace the '?'s with NaN\n",
        "cc_apps = cc_apps.replace('?', np.nan)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8epe-khaEDD",
        "outputId": "d3a7a833-d6ed-4d15-8506-605cd7087ae1"
      },
      "source": [
        "cc_apps.isnull().sum()\n",
        "#0,3,4,5,6-->categorical\n",
        "#1,13-->numerical"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     12\n",
              "1     12\n",
              "2      0\n",
              "3      6\n",
              "4      6\n",
              "5      9\n",
              "6      9\n",
              "7      0\n",
              "8      0\n",
              "9      0\n",
              "10     0\n",
              "11     0\n",
              "12     0\n",
              "13    13\n",
              "14     0\n",
              "15     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpOHNpvycDiS",
        "outputId": "0a86de06-a1bd-4dde-ee38-ab1f713202c5"
      },
      "source": [
        "cc_apps.fillna(cc_apps.mean(), inplace=True)\n",
        "\n",
        "# Count the number of NaNs in the dataset to verify\n",
        "print('Total NaN: ' + str(cc_apps.isnull().values.sum()))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total NaN: 67\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyCzmzUxc5UU"
      },
      "source": [
        "for col in cc_apps:\n",
        "    # Check if the column is of object type\n",
        "    if cc_apps[col].dtypes == 'object':\n",
        "        # Impute with the most frequent value\n",
        "        cc_apps = cc_apps.fillna(cc_apps[col].value_counts().index[0])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xySbu_CdWLt",
        "outputId": "e1a10133-f537-431b-c1de-30b7feac68a5"
      },
      "source": [
        "print('Total missing values:' + str(cc_apps.isnull().values.sum()))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total missing values:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "gkY5KZuOduRc",
        "outputId": "7bd773f6-6aa8-4d1c-8791-2cc3aaf58221"
      },
      "source": [
        "print(cc_apps[15].value_counts())\n",
        "import seaborn as sns\n",
        "sns.countplot(cc_apps[15])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-    383\n",
            "+    307\n",
            "Name: 15, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fd74826eb90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSVFMG4tdbfI"
      },
      "source": [
        "## Label Encoders only for target variables with categorical features\n",
        "\n",
        "when used on independent categorical features, numbers are assigned in alphabetical order so values with larger values get biased by the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R74c-A1LdZTG",
        "outputId": "dccd504a-4560-44bd-94b2-da4d671f3905"
      },
      "source": [
        "## only for target variables with categorical features\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# Instantiate LabelEncoder\n",
        "le = LabelEncoder()\n",
        "# Iterate over all the values of each column and extract their dtypes\n",
        "for col in cc_apps:\n",
        "    # Compare if the dtype is object\n",
        "    if cc_apps[col].dtypes =='object':\n",
        "    # Use LabelEncoder to do the numeric transformation\n",
        "        le.fit(cc_apps[col])\n",
        "        cc_apps[col]=le.transform(cc_apps[col])\n",
        "#  information of the new dataframe\n",
        "cc_apps.info()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 690 entries, 0 to 689\n",
            "Data columns (total 16 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   0       690 non-null    int64  \n",
            " 1   1       690 non-null    int64  \n",
            " 2   2       690 non-null    float64\n",
            " 3   3       690 non-null    int64  \n",
            " 4   4       690 non-null    int64  \n",
            " 5   5       690 non-null    int64  \n",
            " 6   6       690 non-null    int64  \n",
            " 7   7       690 non-null    float64\n",
            " 8   8       690 non-null    int64  \n",
            " 9   9       690 non-null    int64  \n",
            " 10  10      690 non-null    int64  \n",
            " 11  11      690 non-null    int64  \n",
            " 12  12      690 non-null    int64  \n",
            " 13  13      690 non-null    int64  \n",
            " 14  14      690 non-null    int64  \n",
            " 15  15      690 non-null    int64  \n",
            "dtypes: float64(2), int64(14)\n",
            "memory usage: 86.4 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "dbXGsvnagXdU",
        "outputId": "afbe5af1-180f-4d9d-8bdc-c218e4a9d966"
      },
      "source": [
        "cc_apps.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>156</td>\n",
              "      <td>0.000</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>8</td>\n",
              "      <td>1.25</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>68</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>328</td>\n",
              "      <td>4.460</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>3.04</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>560</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>89</td>\n",
              "      <td>0.500</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>1.50</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>96</td>\n",
              "      <td>824</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>125</td>\n",
              "      <td>1.540</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>8</td>\n",
              "      <td>3.75</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>43</td>\n",
              "      <td>5.625</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>8</td>\n",
              "      <td>1.71</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>37</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0    1      2   3   4   5   6     7   8   9   10  11  12  13   14  15\n",
              "0   1  156  0.000   2   1  13   8  1.25   1   1   1   0   0  68    0   0\n",
              "1   0  328  4.460   2   1  11   4  3.04   1   1   6   0   0  11  560   0\n",
              "2   0   89  0.500   2   1  11   4  1.50   1   0   0   0   0  96  824   0\n",
              "3   1  125  1.540   2   1  13   8  3.75   1   1   5   1   0  31    3   0\n",
              "4   1   43  5.625   2   1  13   8  1.71   1   0   0   0   2  37    0   0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fra6oJEeeGdC",
        "outputId": "be9d5e77-65ad-4463-f8bb-6e0911b87124"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Drop the features 11 and 13 and convert the DataFrame to a NumPy array\n",
        "cc_apps = cc_apps.drop([11, 13], axis=1)\n",
        "print(cc_apps.head())\n",
        "cc_apps = cc_apps.values\n",
        "\n",
        "# Segregate features and labels into separate variables\n",
        "X,y = cc_apps[:,0:12] , cc_apps[:,13]\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,\n",
        "                                y,\n",
        "                                test_size=0.33,\n",
        "                                random_state=42)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   0    1      2   3   4   5   6     7   8   9   10  12   14  15\n",
            "0   1  156  0.000   2   1  13   8  1.25   1   1   1   0    0   0\n",
            "1   0  328  4.460   2   1  11   4  3.04   1   1   6   0  560   0\n",
            "2   0   89  0.500   2   1  11   4  1.50   1   0   0   0  824   0\n",
            "3   1  125  1.540   2   1  13   8  3.75   1   1   5   0    3   0\n",
            "4   1   43  5.625   2   1  13   8  1.71   1   0   0   2    0   0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muPSDWdNeUvk"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Instantiate MinMaxScaler and use it to rescale X_train and X_test\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "rescaledX_train = scaler.fit_transform(X_train)\n",
        "rescaledX_test = scaler.fit_transform(X_test)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZPwg29qehvQ",
        "outputId": "2e4c989a-8f2d-49bf-f726-cef1130fad4b"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "# Instantiate a LogisticRegression classifier with default parameter values\n",
        "logreg = LogisticRegression()\n",
        "\n",
        "# Fit logreg to the train set\n",
        "logreg.fit(rescaledX_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgTsv5-YmVIq"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0IWYnjHelGI",
        "outputId": "03655710-93e9-43b0-9c1d-417ea4942573"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "# Use logreg to predict instances from the test set and store it\n",
        "y_pred = logreg.predict(rescaledX_test)\n",
        "\n",
        "# Get the accuracy score of logreg model and print it\n",
        "print(\"Accuracy of logistic regression classifier: \", logreg.score(rescaledX_test, y_test))\n",
        "\n",
        "# Print the confusion matrix of the logreg model\n",
        "print('Confusion matrix: \\n ', confusion_matrix(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of logistic regression classifier:  0.8377192982456141\n",
            "Confusion matrix: \n",
            "  [[93 10]\n",
            " [27 98]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pFsBHMYe1wG"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "# Define the grid of values for tol and max_iter\n",
        "tol = [0.01, 0.001, 0.0001]\n",
        "max_iter = [100, 150, 200,500]\n",
        "penalty=['l2','l1','elasticnet', 'none']\n",
        "C=np.logspace(-4, 4,20)\n",
        "solver=[\"lbfgs\", \"newton-cg\", \"liblinear\", \"sag\",\"saga\"]\n",
        "\n",
        "# Create a dictionary where tol and max_iter are keys and the lists of their values are corresponding values\n",
        "param_grid = dict(tol= tol, max_iter= max_iter, penalty=penalty, C=C, solver=solver)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30EAem2wfJR6",
        "outputId": "2b4cb9a6-0c4c-434e-b373-43676be7b545"
      },
      "source": [
        "grid_model = RandomizedSearchCV(estimator=logreg,param_distributions=param_grid, cv=5, verbose=1, n_jobs=-1)\n",
        "\n",
        "# Use scaler to rescale X and assign it to rescaledX\n",
        "rescaledX = scaler.fit_transform(X)\n",
        "\n",
        "# Fit data to grid_model\n",
        "grid_model_result = grid_model.fit(rescaledX, y) ## on whole dataset\n",
        "\n",
        "# Summarize results\n",
        "best_score, best_params = grid_model_result.best_score_, grid_model_result.best_params_\n",
        "print(\"Best: %f using %s\" % (best_score, best_params))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best: 0.849275 using {'tol': 0.0001, 'solver': 'sag', 'penalty': 'none', 'max_iter': 200, 'C': 206.913808111479}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    1.3s finished\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1Pcyb1pfZKb"
      },
      "source": [
        "final_model=grid_model_result.best_estimator_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lTzD9bsffed",
        "outputId": "a6b6b327-b127-44c4-e967-97396def264e"
      },
      "source": [
        "final_model.fit(rescaledX_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=206.913808111479, class_weight=None, dual=False,\n",
              "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
              "                   max_iter=200, multi_class='auto', n_jobs=None,\n",
              "                   penalty='none', random_state=None, solver='sag', tol=0.0001,\n",
              "                   verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8tPqE56fkWr",
        "outputId": "31bc3b57-07cd-4786-ab94-78e045257e19"
      },
      "source": [
        "y_pred_final = final_model.predict(rescaledX_test)\n",
        "\n",
        "# Get the accuracy score of logreg model and print it\n",
        "print(\"Accuracy of logistic regression classifier: \", final_model.score(rescaledX_test, y_test))\n",
        "\n",
        "# Print the confusion matrix of the logreg model\n",
        "print('Confusion matrix: \\n ', confusion_matrix(y_test, y_pred_final))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of logistic regression classifier:  0.8464912280701754\n",
            "Confusion matrix: \n",
            "  [[94  9]\n",
            " [26 99]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "cA_xCn6GoI99",
        "outputId": "8bfd5593-7ac4-4844-a553-1925e16fb87d"
      },
      "source": [
        "cc_apps.head()\n",
        "## curse of dimensionality, on one hot encodingS"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>2</th>\n",
              "      <th>7</th>\n",
              "      <th>10</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>0_b</th>\n",
              "      <th>1_15.17</th>\n",
              "      <th>1_15.75</th>\n",
              "      <th>1_15.83</th>\n",
              "      <th>1_15.92</th>\n",
              "      <th>1_16.00</th>\n",
              "      <th>1_16.08</th>\n",
              "      <th>1_16.17</th>\n",
              "      <th>1_16.25</th>\n",
              "      <th>1_16.33</th>\n",
              "      <th>1_16.50</th>\n",
              "      <th>1_16.92</th>\n",
              "      <th>1_17.08</th>\n",
              "      <th>1_17.25</th>\n",
              "      <th>1_17.33</th>\n",
              "      <th>1_17.42</th>\n",
              "      <th>1_17.50</th>\n",
              "      <th>1_17.58</th>\n",
              "      <th>1_17.67</th>\n",
              "      <th>1_17.83</th>\n",
              "      <th>1_17.92</th>\n",
              "      <th>1_18.00</th>\n",
              "      <th>1_18.08</th>\n",
              "      <th>1_18.17</th>\n",
              "      <th>1_18.25</th>\n",
              "      <th>1_18.33</th>\n",
              "      <th>1_18.42</th>\n",
              "      <th>1_18.50</th>\n",
              "      <th>1_18.58</th>\n",
              "      <th>1_18.67</th>\n",
              "      <th>1_18.75</th>\n",
              "      <th>1_18.83</th>\n",
              "      <th>1_18.92</th>\n",
              "      <th>1_19.00</th>\n",
              "      <th>1_19.17</th>\n",
              "      <th>...</th>\n",
              "      <th>13_00410</th>\n",
              "      <th>13_00411</th>\n",
              "      <th>13_00416</th>\n",
              "      <th>13_00420</th>\n",
              "      <th>13_00422</th>\n",
              "      <th>13_00431</th>\n",
              "      <th>13_00432</th>\n",
              "      <th>13_00434</th>\n",
              "      <th>13_00440</th>\n",
              "      <th>13_00443</th>\n",
              "      <th>13_00450</th>\n",
              "      <th>13_00454</th>\n",
              "      <th>13_00455</th>\n",
              "      <th>13_00460</th>\n",
              "      <th>13_00465</th>\n",
              "      <th>13_00470</th>\n",
              "      <th>13_00480</th>\n",
              "      <th>13_00487</th>\n",
              "      <th>13_00491</th>\n",
              "      <th>13_00500</th>\n",
              "      <th>13_00510</th>\n",
              "      <th>13_00515</th>\n",
              "      <th>13_00519</th>\n",
              "      <th>13_00520</th>\n",
              "      <th>13_00523</th>\n",
              "      <th>13_00550</th>\n",
              "      <th>13_00560</th>\n",
              "      <th>13_00583</th>\n",
              "      <th>13_00600</th>\n",
              "      <th>13_00640</th>\n",
              "      <th>13_00680</th>\n",
              "      <th>13_00711</th>\n",
              "      <th>13_00720</th>\n",
              "      <th>13_00760</th>\n",
              "      <th>13_00840</th>\n",
              "      <th>13_00928</th>\n",
              "      <th>13_00980</th>\n",
              "      <th>13_01160</th>\n",
              "      <th>13_02000</th>\n",
              "      <th>13_b</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000</td>\n",
              "      <td>1.25</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.460</td>\n",
              "      <td>3.04</td>\n",
              "      <td>6</td>\n",
              "      <td>560</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.500</td>\n",
              "      <td>1.50</td>\n",
              "      <td>0</td>\n",
              "      <td>824</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.540</td>\n",
              "      <td>3.75</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.625</td>\n",
              "      <td>1.71</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  559 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       2     7  10   14  15  ...  13_00928  13_00980  13_01160  13_02000  13_b\n",
              "0  0.000  1.25   1    0   0  ...         0         0         0         0     0\n",
              "1  4.460  3.04   6  560   0  ...         0         0         0         0     0\n",
              "2  0.500  1.50   0  824   0  ...         0         0         0         0     0\n",
              "3  1.540  3.75   5    3   0  ...         0         0         0         0     0\n",
              "4  5.625  1.71   0    0   0  ...         0         0         0         0     0\n",
              "\n",
              "[5 rows x 559 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXcM-bKulluf"
      },
      "source": [
        "Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgJOwmvdXhdX",
        "outputId": "9f552815-6591-4f21-b382-ad230e968be5"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "nb=GaussianNB()\n",
        "nb.fit(rescaledX_train, y_train)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB(priors=None, var_smoothing=1e-09)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-QAhEXvl9E1"
      },
      "source": [
        "nb_pred=nb.predict(rescaledX_test)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gb6UGZsAmFv2",
        "outputId": "6af70254-84b5-4786-e368-90742cdbb331"
      },
      "source": [
        "# Get the accuracy score of logreg model and print it\n",
        "print(\"Accuracy of NB classifier: \", nb.score(rescaledX_test, y_test))\n",
        "\n",
        "# Print the confusion matrix of the logreg model\n",
        "print('Confusion matrix: \\n ', confusion_matrix(y_test, nb_pred))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of NB classifier:  0.8245614035087719\n",
            "Confusion matrix: \n",
            "  [[ 83  20]\n",
            " [ 20 105]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbLLiqekmZxJ"
      },
      "source": [
        "#Stochastic Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzm_D5sNmSYl",
        "outputId": "1b724705-c65c-4c0d-9e3b-f3b8bd6d0b0a"
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "sgd=SGDClassifier(loss=\"modified_huber\",shuffle=True,random_state=101)\n",
        "sgd.fit(rescaledX_train, y_train)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
              "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
              "              l1_ratio=0.15, learning_rate='optimal', loss='modified_huber',\n",
              "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
              "              power_t=0.5, random_state=101, shuffle=True, tol=0.001,\n",
              "              validation_fraction=0.1, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmRuRoA-msNX"
      },
      "source": [
        "sgd_pred=nb.predict(rescaledX_test)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCyQDDhhm9Ma",
        "outputId": "11013fd6-9c89-42a7-ada8-f7144440aa6c"
      },
      "source": [
        "# Get the accuracy score of logreg model and print it\n",
        "print(\"Accuracy of  SGDclassifier: \", sgd.score(rescaledX_test, y_test))\n",
        "\n",
        "# Print the confusion matrix of the logreg model\n",
        "print('Confusion matrix: \\n ', confusion_matrix(y_test, sgd_pred))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of  SGDclassifier:  0.8421052631578947\n",
            "Confusion matrix: \n",
            "  [[ 83  20]\n",
            " [ 20 105]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMQEPecTnFCW"
      },
      "source": [
        "#K-Nearest Neighbours"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x94S6TOZnCFh",
        "outputId": "cb3c32ff-d29c-481c-8d17-598b482ec09d"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn=KNeighborsClassifier(n_neighbors=4, n_jobs=-1)\n",
        "knn.fit(rescaledX_train, y_train)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=-1, n_neighbors=4, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUy2KkI4ncTn"
      },
      "source": [
        "knn_pred=knn.predict(rescaledX_test)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMPUWzQ9nj-k",
        "outputId": "e42607a1-aaa7-4eea-f7ce-138e7d07ca4a"
      },
      "source": [
        "# Get the accuracy score of logreg model and print it\n",
        "print(\"Accuracy of  KNN classifier: \", knn.score(rescaledX_test, y_test))\n",
        "\n",
        "# Print the confusion matrix of the logreg model\n",
        "print('Confusion matrix: \\n ', confusion_matrix(y_test, knn_pred))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of  KNN classifier:  0.8728070175438597\n",
            "Confusion matrix: \n",
            "  [[ 94   9]\n",
            " [ 20 105]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBK4mplXogKi"
      },
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yL7SXz_nz5Y",
        "outputId": "d130553b-6a40-4bcf-cce4-fdb14e9dd29f"
      },
      "source": [
        "acc=accuracy_score(y_test, knn_pred)\n",
        "print(\"Accuracy Score\", acc)\n",
        "cr=classification_report(y_test, knn_pred)\n",
        "print(\"Classification Report\", cr)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score 0.8728070175438597\n",
            "Classification Report               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.82      0.91      0.87       103\n",
            "         1.0       0.92      0.84      0.88       125\n",
            "\n",
            "    accuracy                           0.87       228\n",
            "   macro avg       0.87      0.88      0.87       228\n",
            "weighted avg       0.88      0.87      0.87       228\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1j-ztpIpgC7"
      },
      "source": [
        "XGBoost CLassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_Hlc_Ghn93L",
        "outputId": "45185319-3a35-44b8-ab50-3d7fc817668a"
      },
      "source": [
        "import xgboost as xgb\n",
        "xg=xgb.XGBClassifier(random_state=1,learning_rate=0.01)\n",
        "xg.fit(rescaledX_train, y_train)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.01, max_delta_step=0, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=1,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-jRkjNPppvb"
      },
      "source": [
        "xg_pred=xg.predict(rescaledX_test)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_-BtX--pupt",
        "outputId": "1e68f6b1-2691-4dd6-806b-26108af61331"
      },
      "source": [
        "print(\"Accuracy of  SGDclassifier: \", xg.score(rescaledX_test, y_test))\n",
        "\n",
        "# Print the confusion matrix of the logreg model\n",
        "print('Confusion matrix: \\n ', confusion_matrix(y_test, xg_pred))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of  SGDclassifier:  0.8508771929824561\n",
            "Confusion matrix: \n",
            "  [[ 94   9]\n",
            " [ 25 100]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tC148rPp-eB"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWcswVtAp7_-",
        "outputId": "15a4b781-77fa-4d31-f6b1-27eca8bcacb9"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf=RandomForestClassifier(n_estimators=200, criterion=\"entropy\")\n",
        "rf.fit(rescaledX_train, y_train)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='entropy', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lL7aoSz-qOV4"
      },
      "source": [
        "rf_pred=rf.predict(rescaledX_test)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNEKqHofqT_S",
        "outputId": "7d9fc6e0-1787-4fd1-ec98-8afd88ee7a7c"
      },
      "source": [
        "print(\"Accuracy of   Random Forest classifier: \", rf.score(rescaledX_test, y_test))\n",
        "\n",
        "# Print the confusion matrix of the logreg model\n",
        "print('Confusion matrix: \\n ', confusion_matrix(y_test, rf_pred))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of   Random Forest classifier:  0.868421052631579\n",
            "Confusion matrix: \n",
            "  [[ 92  11]\n",
            " [ 19 106]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKHedx2FqbJ7"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt','log2']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(10, 1000,10)]\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10,14]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4,6,8]\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "              'criterion':['entropy','gini']}"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZ11ugV4rLNx",
        "outputId": "e4e694c7-d0f1-4a84-f706-9e6d368fbf45"
      },
      "source": [
        "rf_randomcv=RandomizedSearchCV(estimator=rf,param_distributions=random_grid,n_iter=1,cv=3,verbose=2,\n",
        "                               random_state=100,n_jobs=-1)\n",
        "rf_randomcv.fit(rescaledX_train, y_train)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.9s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score=nan,\n",
              "                   estimator=RandomForestClassifier(bootstrap=True,\n",
              "                                                    ccp_alpha=0.0,\n",
              "                                                    class_weight=None,\n",
              "                                                    criterion='entropy',\n",
              "                                                    max_depth=None,\n",
              "                                                    max_features='auto',\n",
              "                                                    max_leaf_nodes=None,\n",
              "                                                    max_samples=None,\n",
              "                                                    min_impurity_decrease=0.0,\n",
              "                                                    min_impurity_split=None,\n",
              "                                                    min_samples_leaf=1,\n",
              "                                                    min_samples_split=2,\n",
              "                                                    min_weight_fraction_leaf=0.0,\n",
              "                                                    n_estimators=200,\n",
              "                                                    n_j...\n",
              "                   param_distributions={'criterion': ['entropy', 'gini'],\n",
              "                                        'max_depth': [10, 120, 230, 340, 450,\n",
              "                                                      560, 670, 780, 890,\n",
              "                                                      1000],\n",
              "                                        'max_features': ['auto', 'sqrt',\n",
              "                                                         'log2'],\n",
              "                                        'min_samples_leaf': [1, 2, 4, 6, 8],\n",
              "                                        'min_samples_split': [2, 5, 10, 14],\n",
              "                                        'n_estimators': [200, 400, 600, 800,\n",
              "                                                         1000, 1200, 1400, 1600,\n",
              "                                                         1800, 2000]},\n",
              "                   pre_dispatch='2*n_jobs', random_state=100, refit=True,\n",
              "                   return_train_score=False, scoring=None, verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmkCESsfrSLD",
        "outputId": "b92d1aaf-c9fe-4c48-a7d1-647f769127d7"
      },
      "source": [
        "rf_randomcv.best_score_,rf_randomcv.best_params_"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8744588744588745,\n",
              " {'criterion': 'entropy',\n",
              "  'max_depth': 1000,\n",
              "  'max_features': 'sqrt',\n",
              "  'min_samples_leaf': 2,\n",
              "  'min_samples_split': 2,\n",
              "  'n_estimators': 200})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31pXzM97rbia"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}